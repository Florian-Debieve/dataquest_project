{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1433282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debie\\Documents\\anaconda_space\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\\\Users\\\\debie\\\\Documents\\\\anaconda_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ff558",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59890d96",
   "metadata": {},
   "source": [
    "In this project we're going to study the practical side of the Naive Bayes algorithm by building a spam filter for SMS messages.\n",
    "\n",
    "To classify messages as spam or non-spam, a computer:\n",
    "\n",
    "    Learns how humans classify messages.\n",
    "    Uses that human knowledge to estimate probabilities for new messages — probabilities for spam and non-spam.\n",
    "    Classifies a new message based on these probability values — if the probability for spam is greater, then it classifies the message as spam. Otherwise, it classifies it as non-spam (if the two probability values are equal, then we may need a human to classify the message).\n",
    "\n",
    "So our first task is to \"teach\" the computer how to classify messages. To do that, we'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans. The SMS are classified in 2 categories inside the dataset: spam (unwanted message) and ham (normal message)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b7091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46a9b2d",
   "metadata": {},
   "source": [
    "Let's look into the SMS dataset we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37886827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Label   5572 non-null   object\n",
      " 1   SMS     5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sms = pd.read_csv(\"SMSSpamCollection\", sep='\\t', header=None, names=[\"Label\", \"SMS\"])\n",
    "\n",
    "sms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5481c82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f48fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['Label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75e352",
   "metadata": {},
   "source": [
    "There are 13 % of messages that are spam and 87% that are ham (not spam)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc31b71",
   "metadata": {},
   "source": [
    "For the purpose of testing the spam filter that we will create, we will split the datset into 2 categories:\n",
    "\n",
    "    A training set that will be used to train the computer to classify the  sms. It will have 4458 messages (around 80 % of the dataset).\n",
    "\n",
    "    A test set that will be used to test our spam filter and check if it is efficient. It will have 1114 messages (around 20 % of the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8976d75c",
   "metadata": {},
   "source": [
    "First we randomize the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df591f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: ham     0.86541\n",
      "spam    0.13459\n",
      "Name: Label, dtype: float64\n",
      "Test dataset: ham     0.868043\n",
      "spam    0.131957\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sms_r = sms.sample(frac = 1, random_state = 1)\n",
    "\n",
    "training = sms_r.iloc[:4458, :]\n",
    "training.reset_index(drop = True, inplace = True)\n",
    "\n",
    "test = sms_r.iloc[4458:, :]\n",
    "test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "print('Training dataset:', training['Label'].value_counts(normalize = True))\n",
    "\n",
    "print('Test dataset:', test['Label'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "881b7e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e2fce",
   "metadata": {},
   "source": [
    "The 2 datasets have approximately the same proportion of spam and ham."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ceefe8",
   "metadata": {},
   "source": [
    "In order to make the calculations of the probability that a message is a spam, we need to transform the dataset as follow:\n",
    "\n",
    "\n",
    "    - The SMS column doesn't exist anymore.\n",
    "    - Instead, the SMS column is replaced by a series of new columns, where each column represents a unique word from the vocabulary.\n",
    "    - Each row describes a single message. For instance, the first row corresponds to the message \"SECRET PRIZE! CLAIM SECRET PRIZE NOW!!\", and it  has the values spam, 2, 2, 1, 1, 0, 0, 0, 0, 0. These values tell us    that:\n",
    "        The message is spam.\n",
    "        The word \"secret\" occurs two times inside the message.\n",
    "        The word \"prize\" occurs two times inside the message.\n",
    "        The word \"claim\" occurs one time inside the message.\n",
    "        The word \"now\" occurs one time inside the message.\n",
    "        The words \"coming\", \"to\", \"my\", \"party\", and \"winner\" occur zero times inside the message.\n",
    "    - All words in the vocabulary are in lower case, so \"SECRET\" and \"secret\" come to be considered to be the same word.\n",
    "    - Punctuation is not taken into account anymore (for instance, we can't look at the table and conclude that the first message initially had three exclamation marks).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c873fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0afa7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "training['SMS'] = training['SMS'].str.replace('\\W', ' ')\n",
    "training['SMS'] = training['SMS'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71073cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be3d2a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "training[\"SMS\"] = training[\"SMS\"].str.split()\n",
    "vocabulary = []\n",
    "for words in training['SMS']:\n",
    "    for word in words:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d5b5f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c7da0d",
   "metadata": {},
   "source": [
    "We have all the words contained in the messages of the training dataset that are listed in \"vocabulary\", there are 7783 different words.\n",
    "\n",
    "Now, we will count how many time each word in the list \"vocabulary\" appears in each SMS and then add this count to the datframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "353145d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        \n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "training_words = pd.concat([training, word_counts], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "493758ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lobby</th>\n",
       "      <th>asleep</th>\n",
       "      <th>forgive</th>\n",
       "      <th>hunks</th>\n",
       "      <th>asp</th>\n",
       "      <th>astoundingly</th>\n",
       "      <th>edukkukayee</th>\n",
       "      <th>missing</th>\n",
       "      <th>disturb</th>\n",
       "      <th>09053750005</th>\n",
       "      <th>...</th>\n",
       "      <th>gauti</th>\n",
       "      <th>double</th>\n",
       "      <th>apo</th>\n",
       "      <th>belly</th>\n",
       "      <th>macedonia</th>\n",
       "      <th>bettersn</th>\n",
       "      <th>moral</th>\n",
       "      <th>rolled</th>\n",
       "      <th>3d</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lobby  asleep  forgive  hunks  asp  astoundingly  edukkukayee  missing  \\\n",
       "0      0       0        0      0    0             0            0        0   \n",
       "1      0       0        0      0    0             0            0        0   \n",
       "2      0       0        0      0    0             0            0        0   \n",
       "3      0       0        0      0    0             0            0        0   \n",
       "4      0       0        0      0    0             0            0        0   \n",
       "\n",
       "   disturb  09053750005  ...  gauti  double  apo  belly  macedonia  bettersn  \\\n",
       "0        0            0  ...      0       0    0      0          0         0   \n",
       "1        0            0  ...      0       0    0      0          0         0   \n",
       "2        0            0  ...      0       0    0      0          0         0   \n",
       "3        0            0  ...      0       0    0      0          0         0   \n",
       "4        0            0  ...      0       0    0      0          0         0   \n",
       "\n",
       "   moral  rolled  3d  en  \n",
       "0      0       0   0   0  \n",
       "1      0       0   0   0  \n",
       "2      0       0   0   0  \n",
       "3      0       0   0   0  \n",
       "4      0       0   0   0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee900c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>lobby</th>\n",
       "      <th>asleep</th>\n",
       "      <th>forgive</th>\n",
       "      <th>hunks</th>\n",
       "      <th>asp</th>\n",
       "      <th>astoundingly</th>\n",
       "      <th>edukkukayee</th>\n",
       "      <th>missing</th>\n",
       "      <th>...</th>\n",
       "      <th>gauti</th>\n",
       "      <th>double</th>\n",
       "      <th>apo</th>\n",
       "      <th>belly</th>\n",
       "      <th>macedonia</th>\n",
       "      <th>bettersn</th>\n",
       "      <th>moral</th>\n",
       "      <th>rolled</th>\n",
       "      <th>3d</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  lobby  asleep  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]      0       0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...      0       0   \n",
       "2   ham                    [welp, apparently, he, retired]      0       0   \n",
       "3   ham                                           [havent]      0       0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...      0       0   \n",
       "\n",
       "   forgive  hunks  asp  astoundingly  edukkukayee  missing  ...  gauti  \\\n",
       "0        0      0    0             0            0        0  ...      0   \n",
       "1        0      0    0             0            0        0  ...      0   \n",
       "2        0      0    0             0            0        0  ...      0   \n",
       "3        0      0    0             0            0        0  ...      0   \n",
       "4        0      0    0             0            0        0  ...      0   \n",
       "\n",
       "   double  apo  belly  macedonia  bettersn  moral  rolled  3d  en  \n",
       "0       0    0      0          0         0      0       0   0   0  \n",
       "1       0    0      0          0         0      0       0   0   0  \n",
       "2       0    0      0          0         0      0       0   0   0  \n",
       "3       0    0      0          0         0      0       0   0   0  \n",
       "4       0    0      0          0         0      0       0   0   0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79be157",
   "metadata": {},
   "source": [
    "Now that we're done with data cleaning and have a training set to work with, we can begin creating the spam filter.\n",
    "\n",
    "To calculate the probability tha a message is a spam given the words it contains, we first need to calculate P(Spam), P(Ham), Nspam, Nham and Nvocabulary.\n",
    "\n",
    "Nspam equal to the number of words in all the spam messages.\n",
    "\n",
    "Nham equal to the number of words in all the non-spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8398f089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     3858\n",
       "spam     600\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d02deae",
   "metadata": {},
   "source": [
    "According to the value_counts above we can determine the value of Pspam and Pham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c16a40f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13458950201884254 0.8654104979811574\n"
     ]
    }
   ],
   "source": [
    "p_spam = 600 / (3858 + 600)\n",
    "p_ham = 1 - p_spam\n",
    "print(p_spam,p_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ab02d",
   "metadata": {},
   "source": [
    "Now we'll determine Nspam, Nham and Nvocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f21d59aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nspam =  15190\n",
      "Nham =  57237\n",
      "Nvocabulary =  7783\n"
     ]
    }
   ],
   "source": [
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "n_spam = 0\n",
    "for words in training_words[training_words['Label'] == 'spam']['SMS']:\n",
    "    n_spam += len(words)\n",
    "    \n",
    "n_ham = 0\n",
    "for words in training_words[training_words['Label'] == 'ham']['SMS']:\n",
    "    n_ham += len(words)\n",
    "    \n",
    "print('Nspam = ', n_spam)\n",
    "print('Nham = ', n_ham)\n",
    "print('Nvocabulary = ', n_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586ea671",
   "metadata": {},
   "source": [
    "We'll also use Laplace smoothing and set α = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b3b571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fb140",
   "metadata": {},
   "source": [
    "Now we can calculate the parameters P(wi|spam) and P(wi|ham) which are the probabilities that a word wi appears in a message given that the message is a spam or a ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00ad1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "training_spam = training_words[training_words['Label'] == 'spam']\n",
    "training_ham = training_words[training_words['Label'] == 'ham']\n",
    "\n",
    "for word in vocabulary:\n",
    "    parameters_spam[word] = (training_spam[word].sum() + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    parameters_ham[word] = (training_ham[word].sum() + alpha) / (n_ham + alpha * n_vocabulary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11525c14",
   "metadata": {},
   "source": [
    "Now that we've calculated all the constants and parameters we need, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "\n",
    "    Takes in as input a new message (w1, w2, ..., wn)\n",
    "    Calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)\n",
    "    Compares the values of P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn), and:\n",
    "        If P(Ham|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), then the message is classified as ham.\n",
    "        If P(Ham|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), then the message is classified as spam.\n",
    "        If P(Ham|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), then the algorithm may request human help.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea201988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcca98e",
   "metadata": {},
   "source": [
    "Let's try the function on 2 messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cd38aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dd333a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0a18e",
   "metadata": {},
   "source": [
    "The spam filter is now complete, we'll just make a little modification to return the labels instead of printing them.\n",
    "\n",
    "Then we'll measure its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2728067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5165fd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['predicted'] = test['SMS'].apply(classify_test_set)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "635bfabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1100\n",
      "Incorrect: 14\n",
      "Accuracy: 0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 1114\n",
    "    \n",
    "for row in test.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed85d6",
   "metadata": {},
   "source": [
    "The accuracy is around 99 %, it is excellent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
