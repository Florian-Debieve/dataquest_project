{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d0ae775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debie\\Documents\\kaggle\\Disaster Tweets\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\debie\\Documents\\kaggle\\Disaster Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c35129",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Disaster Tweets\n",
    "\n",
    "In this project, we'll work on a dataset which contains more than 7000 tweets. Each of these tweets, are classified in the dataset to indicate if it is about a disaster (flood, forest fire, earthquake, ...) or not. \n",
    "The aim is to build a machine learning model that predicts which tweets are about real disasters and which one’s aren’t.\n",
    "\n",
    "This dataset is taken from a \"competition\" taking place on kaggle website (https://www.kaggle.com/competitions/nlp-getting-started/). It is divided into 2 subsets, one training set and one testing set. The training set (train) has a column indicating if yes or no the tweet is about a disaster. The testing set (holdout) doesn't have this column. Indeed, as it is a \"competition\" (even if it is just for learning how to perform natural language processing), each participant needs to submit the predictions for the tweets in the testing set, and then kaggle will note the accuracy of the submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1cd9bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a10cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "holdout = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d23771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa97e718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b770d52",
   "metadata": {},
   "source": [
    "The target column display for each row either a 0 or a 1. If the value is 0 it means that the tweet is not about a disaster, if it is a 1 it means that this is about a disaster.\n",
    "\n",
    "Excluding the id and the target columns, there are 3 columns that can be used to train our algorithm: the keyword, location and text columns. The location column has too many missing values, so we won't use it.\n",
    "\n",
    "We want to investigate the impact of the keywords column on the target column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018a1160",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(set(list(train['keyword'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cbb2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " 'quarantined',\n",
       " 'hijacker',\n",
       " 'casualties',\n",
       " 'catastrophe',\n",
       " 'body%20bagging',\n",
       " 'curfew',\n",
       " 'evacuate',\n",
       " 'blazing',\n",
       " 'debris',\n",
       " 'disaster',\n",
       " 'fatal',\n",
       " 'rainstorm',\n",
       " 'destroyed',\n",
       " 'rescued',\n",
       " 'survivors',\n",
       " 'threat',\n",
       " 'deluge',\n",
       " 'wildfire',\n",
       " 'obliteration',\n",
       " 'hostages',\n",
       " 'screamed',\n",
       " 'cliff%20fall',\n",
       " 'burning%20buildings',\n",
       " 'chemical%20emergency',\n",
       " 'siren',\n",
       " 'inundated',\n",
       " 'bioterrorism',\n",
       " 'bomb',\n",
       " 'wrecked',\n",
       " 'eyewitness',\n",
       " 'bombed',\n",
       " 'injured',\n",
       " 'survived',\n",
       " 'explosion',\n",
       " 'danger',\n",
       " 'demolish',\n",
       " 'forest%20fires',\n",
       " 'injury',\n",
       " 'arsonist',\n",
       " 'suicide%20bombing',\n",
       " 'collision',\n",
       " 'demolition',\n",
       " 'annihilated',\n",
       " 'derailment',\n",
       " 'rescuers',\n",
       " 'dust%20storm',\n",
       " 'crashed',\n",
       " 'earthquake',\n",
       " 'attacked',\n",
       " 'lightning',\n",
       " 'crash',\n",
       " 'destruction',\n",
       " 'hazardous',\n",
       " 'exploded',\n",
       " 'storm',\n",
       " 'whirlwind',\n",
       " 'outbreak',\n",
       " 'devastation',\n",
       " 'epicentre',\n",
       " 'demolished',\n",
       " 'terrorist',\n",
       " 'tornado',\n",
       " 'wounds',\n",
       " 'derailed',\n",
       " 'fatalities',\n",
       " 'meltdown',\n",
       " 'nuclear%20disaster',\n",
       " 'sirens',\n",
       " 'hurricane',\n",
       " 'flooding',\n",
       " 'drown',\n",
       " 'mass%20murder',\n",
       " 'desolation',\n",
       " 'trapped',\n",
       " 'collapsed',\n",
       " 'blizzard',\n",
       " 'obliterated',\n",
       " 'thunderstorm',\n",
       " 'thunder',\n",
       " 'body%20bags',\n",
       " 'drought',\n",
       " 'emergency',\n",
       " 'hail',\n",
       " 'fear',\n",
       " 'crushed',\n",
       " 'first%20responders',\n",
       " 'radiation%20emergency',\n",
       " 'wreck',\n",
       " 'quarantine',\n",
       " 'massacre',\n",
       " 'suicide%20bomber',\n",
       " 'riot',\n",
       " 'tragedy',\n",
       " 'typhoon',\n",
       " 'hellfire',\n",
       " 'attack',\n",
       " 'arson',\n",
       " 'famine',\n",
       " 'sinkhole',\n",
       " 'violent%20storm',\n",
       " 'mass%20murderer',\n",
       " 'derail',\n",
       " 'rubble',\n",
       " 'detonation',\n",
       " 'desolate',\n",
       " 'stretcher',\n",
       " 'fatality',\n",
       " 'weapon',\n",
       " 'annihilation',\n",
       " 'catastrophic',\n",
       " 'bombing',\n",
       " 'buildings%20burning',\n",
       " 'bush%20fires',\n",
       " 'natural%20disaster',\n",
       " 'upheaval',\n",
       " 'airplane%20accident',\n",
       " 'dead',\n",
       " 'armageddon',\n",
       " 'cyclone',\n",
       " 'terrorism',\n",
       " 'inundation',\n",
       " 'police',\n",
       " 'army',\n",
       " 'buildings%20on%20fire',\n",
       " 'bridge%20collapse',\n",
       " 'displaced',\n",
       " 'body%20bag',\n",
       " 'evacuation',\n",
       " 'hijack',\n",
       " 'collide',\n",
       " 'nuclear%20reactor',\n",
       " 'obliterate',\n",
       " 'sandstorm',\n",
       " 'ruin',\n",
       " 'weapons',\n",
       " 'trouble',\n",
       " 'oil%20spill',\n",
       " 'flattened',\n",
       " 'hijacking',\n",
       " 'burned',\n",
       " 'wounded',\n",
       " 'burning',\n",
       " 'electrocuted',\n",
       " 'destroy',\n",
       " 'apocalypse',\n",
       " 'deaths',\n",
       " 'harm',\n",
       " 'accident',\n",
       " 'injuries',\n",
       " 'damage',\n",
       " 'screaming',\n",
       " 'mudslide',\n",
       " 'evacuated',\n",
       " 'drowned',\n",
       " 'wreckage',\n",
       " 'battle',\n",
       " 'wild%20fires',\n",
       " 'drowning',\n",
       " 'rescue',\n",
       " 'refugees',\n",
       " 'rioting',\n",
       " 'deluged',\n",
       " 'suicide%20bomb',\n",
       " 'windstorm',\n",
       " 'blaze',\n",
       " 'snowstorm',\n",
       " 'flood',\n",
       " 'tsunami',\n",
       " 'heat%20wave',\n",
       " 'devastated',\n",
       " 'explode',\n",
       " 'seismic',\n",
       " 'smoke',\n",
       " 'bleeding',\n",
       " 'landslide',\n",
       " 'sunk',\n",
       " 'structural%20failure',\n",
       " 'detonate',\n",
       " 'blood',\n",
       " 'survive',\n",
       " 'hailstorm',\n",
       " 'military',\n",
       " 'war%20zone',\n",
       " 'bloody',\n",
       " 'fire',\n",
       " 'crush',\n",
       " 'emergency%20plan',\n",
       " 'trauma',\n",
       " 'screams',\n",
       " 'twister',\n",
       " 'ambulance',\n",
       " 'ablaze',\n",
       " 'avalanche',\n",
       " 'volcano',\n",
       " 'collided',\n",
       " 'sinking',\n",
       " 'aftershock',\n",
       " 'forest%20fire',\n",
       " 'fire%20truck',\n",
       " 'mayhem',\n",
       " 'blown%20up',\n",
       " 'hostage',\n",
       " 'razed',\n",
       " 'engulfed',\n",
       " 'blew%20up',\n",
       " 'casualty',\n",
       " 'traumatised',\n",
       " 'electrocute',\n",
       " 'collapse',\n",
       " 'panicking',\n",
       " 'bioterror',\n",
       " 'floods',\n",
       " 'pandemonium',\n",
       " 'flames',\n",
       " 'loud%20bang',\n",
       " 'death',\n",
       " 'lava',\n",
       " 'hazard',\n",
       " 'blight',\n",
       " 'emergency%20services',\n",
       " 'panic']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2d2fd2",
   "metadata": {},
   "source": [
    "The keyword column is filled with disaster-related words from the tweet. In this dataset, approximately 99% of the rows have their keyword column filled. This column doesn't add any valuable information about the tweet, let's ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f253b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bis = train.copy()[['text', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40560c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debie\\AppData\\Local\\Temp/ipykernel_21548/110132716.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_bis['text'] = train_bis['text'].str.replace('\\W', ' ')\n",
      "C:\\Users\\debie\\AppData\\Local\\Temp/ipykernel_21548/110132716.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_bis['text'] = train_bis['text'].str.replace('\\d', ' ')\n"
     ]
    }
   ],
   "source": [
    "train_bis['text'] = train_bis['text'].str.replace('\\W', ' ')\n",
    "train_bis['text'] = train_bis['text'].str.replace('\\d', ' ')\n",
    "train_bis['text'] = train_bis['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc3446bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_</th>\n",
       "      <th>target_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds are the reason of this  earthquake m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask  canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all residents asked to  shelter in place  are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people receive  wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent this photo from ruby  alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_  target_\n",
       "0  our deeds are the reason of this  earthquake m...        1\n",
       "1             forest fire near la ronge sask  canada        1\n",
       "2  all residents asked to  shelter in place  are ...        1\n",
       "3         people receive  wildfires evacuation or...        1\n",
       "4  just got sent this photo from ruby  alaska as ...        1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bis.rename(mapper = {'target' : 'target_', 'text' : 'text_'}, axis = 1, inplace = True)\n",
    "train_bis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47fe69",
   "metadata": {},
   "source": [
    "Now we can focus on how to process the text column. We will transform the string in this column into a list containing all the words of the original text. Then, for each unique word found in all the dataset, a column will be created, and if this word is in a tweet the value is set to 1 (0 if it is not).\n",
    "\n",
    "We renamed the \"target\" and \"text\" column into \"target_\" and \"text_\" beacause the words \"target\" and \"text\" are appearing in the tweets and we don't want to create 2 columns with the same name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bc67a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bis['text_'] = train_bis['text_'].str.split()\n",
    "vocabulary = []\n",
    "for words in train_bis['text_']:\n",
    "    for word in words:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dae99c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22261"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6380e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_tweet = {unique_word: [0] * len(train_bis['text_']) for unique_word in vocabulary}\n",
    "\n",
    "for index, tweet in enumerate(train_bis['text_']):\n",
    "    for word in tweet:\n",
    "        word_counts_per_tweet[word][index] += 1\n",
    "        \n",
    "word_counts = pd.DataFrame(word_counts_per_tweet)\n",
    "training_words = pd.concat([train_bis, word_counts], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0720f5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_</th>\n",
       "      <th>target_</th>\n",
       "      <th>denies</th>\n",
       "      <th>ofcourse</th>\n",
       "      <th>ijzcytbffo</th>\n",
       "      <th>exact</th>\n",
       "      <th>stuartbroad</th>\n",
       "      <th>winner</th>\n",
       "      <th>dannyraynard</th>\n",
       "      <th>subreddits</th>\n",
       "      <th>...</th>\n",
       "      <th>knows</th>\n",
       "      <th>vaccine</th>\n",
       "      <th>pulaekxcq</th>\n",
       "      <th>uhc</th>\n",
       "      <th>angelheartnight</th>\n",
       "      <th>outbound</th>\n",
       "      <th>kwwwkwwwk</th>\n",
       "      <th>freebesieged</th>\n",
       "      <th>raf</th>\n",
       "      <th>tantrums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_  target_  denies  \\\n",
       "0  [our, deeds, are, the, reason, of, this, earth...        1       0   \n",
       "1      [forest, fire, near, la, ronge, sask, canada]        1       0   \n",
       "2  [all, residents, asked, to, shelter, in, place...        1       0   \n",
       "3  [people, receive, wildfires, evacuation, order...        1       0   \n",
       "4  [just, got, sent, this, photo, from, ruby, ala...        1       0   \n",
       "\n",
       "   ofcourse  ijzcytbffo  exact  stuartbroad  winner  dannyraynard  subreddits  \\\n",
       "0         0           0      0            0       0             0           0   \n",
       "1         0           0      0            0       0             0           0   \n",
       "2         0           0      0            0       0             0           0   \n",
       "3         0           0      0            0       0             0           0   \n",
       "4         0           0      0            0       0             0           0   \n",
       "\n",
       "   ...  knows  vaccine  pulaekxcq  uhc  angelheartnight  outbound  kwwwkwwwk  \\\n",
       "0  ...      0        0          0    0                0         0          0   \n",
       "1  ...      0        0          0    0                0         0          0   \n",
       "2  ...      0        0          0    0                0         0          0   \n",
       "3  ...      0        0          0    0                0         0          0   \n",
       "4  ...      0        0          0    0                0         0          0   \n",
       "\n",
       "   freebesieged  raf  tantrums  \n",
       "0             0    0         0  \n",
       "1             0    0         0  \n",
       "2             0    0         0  \n",
       "3             0    0         0  \n",
       "4             0    0         0  \n",
       "\n",
       "[5 rows x 22263 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdffba1",
   "metadata": {},
   "source": [
    "As we don't have the target values in the testing set (holdout) provided by kaggle, in order to be able to assess if the algorithms we train are accurate, we divide our training set into 2 subsets. 80% of our training set will be used for training purpose, and the rest for testing the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fc19cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = training_words.drop(['text_', 'target_'], axis =1)\n",
    "all_y = training_words['target_']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    all_X, all_y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10e130f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8537b",
   "metadata": {},
   "source": [
    "For our first try, let's train a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00cebf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8108995403808273\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 1000)\n",
    "lr.fit(train_X, train_y)\n",
    "predictions = lr.predict(test_X)\n",
    "accuracy = accuracy_score(test_y, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb67d0",
   "metadata": {},
   "source": [
    "First try we got 81 % accuracy: not too bad !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "371e62b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['denies',\n",
       " 'ofcourse',\n",
       " 'ijzcytbffo',\n",
       " 'exact',\n",
       " 'stuartbroad',\n",
       " 'winner',\n",
       " 'dannyraynard',\n",
       " 'subreddits',\n",
       " 'empty',\n",
       " 'northern',\n",
       " 'ttdx',\n",
       " 'vxuftvt',\n",
       " 'jblrrnmdsm',\n",
       " 'eto',\n",
       " 'flyopinemonkey',\n",
       " 'rosenthal',\n",
       " 'cannon',\n",
       " 'certificates',\n",
       " 'murderous',\n",
       " 'ftrw',\n",
       " 'intending',\n",
       " 'bark',\n",
       " 'pounding',\n",
       " 'folding',\n",
       " 'ugfpwmy',\n",
       " 'effort',\n",
       " 'hizja',\n",
       " 'waves',\n",
       " 'inroices',\n",
       " 'meltdown',\n",
       " 'demonstrated',\n",
       " 'chris',\n",
       " 'eejyjky',\n",
       " 'niamhosullivanx',\n",
       " 'loop',\n",
       " 'yesterday',\n",
       " 'zn',\n",
       " 'preparedness',\n",
       " 'enterprise',\n",
       " 'sve',\n",
       " 'ykvsttvdwo',\n",
       " 'pst',\n",
       " 'infowars',\n",
       " 'pummel',\n",
       " 'cycling',\n",
       " 'ranking',\n",
       " 'souda',\n",
       " 'isbtzujfbm',\n",
       " 'pmf',\n",
       " 'film',\n",
       " 'wsg',\n",
       " 'daubt',\n",
       " 'udkmadkuzy',\n",
       " 'delmont',\n",
       " 'qfrawln',\n",
       " 'ap',\n",
       " 'mqmcolwbzc',\n",
       " 'annual',\n",
       " 'paj',\n",
       " 'alabama',\n",
       " 'oneself',\n",
       " 'parter',\n",
       " 'chkp',\n",
       " 'bang_me_up_guk',\n",
       " 'jyiegtnc',\n",
       " 'tbe',\n",
       " 'nycbuildings',\n",
       " 'kxjstl',\n",
       " 'stftjcrjea',\n",
       " 'discoverycntr',\n",
       " 'rdg',\n",
       " 'utldif',\n",
       " 'bcpmvylsih',\n",
       " 'battle',\n",
       " 'xssgedsbh',\n",
       " 'urs',\n",
       " 'harperanetflixshow',\n",
       " 'jwdfpyg',\n",
       " 'aseer',\n",
       " 'darkndtatted',\n",
       " 'ultimalucha',\n",
       " 'collegeradi',\n",
       " 'umtffa',\n",
       " 'construct',\n",
       " 'throwin',\n",
       " 'deai',\n",
       " 'miss_homasttopa',\n",
       " 'tnuaciv',\n",
       " 'subcommittee',\n",
       " 'amazondeals',\n",
       " 'mutek_montreal',\n",
       " 'xvlkfcvfx',\n",
       " 'earlier',\n",
       " 'patron',\n",
       " 'younger',\n",
       " 'ambleside',\n",
       " 'digit',\n",
       " 'think',\n",
       " 'watched',\n",
       " 'go',\n",
       " 'hvzlaradio',\n",
       " 'vanpoli',\n",
       " 'zcvfc',\n",
       " 'pcs',\n",
       " 'ends',\n",
       " 'qg',\n",
       " 'plqf',\n",
       " 'good',\n",
       " 'jolly_jinu',\n",
       " 'wtl',\n",
       " 'soaker',\n",
       " 'followlasg',\n",
       " 'gigw',\n",
       " 'gut',\n",
       " 'milf',\n",
       " 'beastin',\n",
       " 'fpryp',\n",
       " 'itzzkwfhg',\n",
       " 'vcfs',\n",
       " 'teamscorpion',\n",
       " 'skims',\n",
       " 'activities',\n",
       " 'dfljev',\n",
       " 'disowned',\n",
       " 'unrecognized',\n",
       " 'many',\n",
       " 'punishing',\n",
       " 'psxp',\n",
       " 'ywwsqj',\n",
       " 'yfy',\n",
       " 'rayner',\n",
       " 'dko',\n",
       " 'bjjoifzuhl',\n",
       " 'xoqz',\n",
       " 'accounts',\n",
       " 'heirs',\n",
       " 'sindh',\n",
       " 'dsmbqkwu',\n",
       " 'libertarianluke',\n",
       " 'owia',\n",
       " 'blks',\n",
       " 'preseason',\n",
       " 'anriombhqn',\n",
       " 'kah',\n",
       " 'eug',\n",
       " 'dbdwtocgxf',\n",
       " 'ufcc',\n",
       " 'final',\n",
       " 'abandoned',\n",
       " 'kfs',\n",
       " 'video',\n",
       " 'skyler',\n",
       " 'dollar',\n",
       " 'cucumber',\n",
       " 'jumped',\n",
       " 'door',\n",
       " 'recipe',\n",
       " 'hypocrisy',\n",
       " 'closet',\n",
       " 'fmuge',\n",
       " 'pour',\n",
       " 'dccomics',\n",
       " 'iphooey',\n",
       " 'gqi',\n",
       " 'sxhgfithjw',\n",
       " 'permission',\n",
       " 'skaausjpo',\n",
       " 'presents',\n",
       " 'dec',\n",
       " 'gwnrhmso',\n",
       " 'qus',\n",
       " 'xnj',\n",
       " 'ufnxxavqs',\n",
       " 'xuebfa',\n",
       " 'ioqm',\n",
       " 'annddd',\n",
       " 'td',\n",
       " 'cubstalk',\n",
       " 'chalked',\n",
       " 'vepu',\n",
       " 'wocowae',\n",
       " 'imouto',\n",
       " 'yamaguchi',\n",
       " 'megadeth',\n",
       " 'romero',\n",
       " 'ipad',\n",
       " 'darchambau',\n",
       " 'reps',\n",
       " 'urged',\n",
       " 'okamsczbwg',\n",
       " 'infomercial',\n",
       " 'trump',\n",
       " 'manutd',\n",
       " 'rip',\n",
       " 'ncwx',\n",
       " 'xmdidgpnr',\n",
       " 'fkn',\n",
       " 'cragtt',\n",
       " 'stadium',\n",
       " 'livingsafely',\n",
       " 'buildup',\n",
       " 'oasw',\n",
       " 'dill',\n",
       " 'fajbxz',\n",
       " 'clapping',\n",
       " 'tenshi',\n",
       " 'crazyideascollege',\n",
       " 'soon',\n",
       " 'brazil',\n",
       " 'hartford',\n",
       " 'brutally',\n",
       " 'feelslikefob',\n",
       " 'ucawg',\n",
       " 'enter',\n",
       " 'bnwygx',\n",
       " 'cfc',\n",
       " 'packs',\n",
       " 'chilis',\n",
       " 'pitched',\n",
       " 'fewmoretweets',\n",
       " 'early',\n",
       " 'pleasant',\n",
       " 'previous',\n",
       " 'came',\n",
       " 'vvorm',\n",
       " 'domesticate',\n",
       " 'ran',\n",
       " 'mkav',\n",
       " 'hhferz',\n",
       " 'ncjlxzfwaa',\n",
       " 'sdsnhm',\n",
       " 'sxar',\n",
       " 'giaxd',\n",
       " 'langtree',\n",
       " 'olzavtjfkh',\n",
       " 'alert',\n",
       " 'slanglucci',\n",
       " 'paulista',\n",
       " 'ledmvezcol',\n",
       " 'maple',\n",
       " 'qgtzq',\n",
       " 'satin',\n",
       " 'igskd',\n",
       " 'bennycapricon',\n",
       " 'dramaa_llama',\n",
       " 'taliban',\n",
       " 'ruor',\n",
       " 'adani',\n",
       " 'steak',\n",
       " 'finish',\n",
       " 'twitter',\n",
       " 'missouri',\n",
       " 'gis',\n",
       " 'kach',\n",
       " 'ossc',\n",
       " 'restaurant',\n",
       " 'quotes',\n",
       " 'outlook',\n",
       " 'bxzzhxkm',\n",
       " 'rollingstones',\n",
       " 'sitep',\n",
       " 'finna',\n",
       " 'cityporn',\n",
       " 'has',\n",
       " 'harshness',\n",
       " 'brockton',\n",
       " 'miì',\n",
       " 'prem',\n",
       " 'ahamedis',\n",
       " 'cbxnhhz',\n",
       " 'gsk',\n",
       " 'qnq',\n",
       " 'rtq',\n",
       " 'deltachildren',\n",
       " 'vb',\n",
       " 'springs',\n",
       " 'ge',\n",
       " 'xvb',\n",
       " 'production',\n",
       " 'kuug',\n",
       " 'saunders',\n",
       " 'gtopyzk',\n",
       " 'travellers',\n",
       " 'axvq',\n",
       " 'canaanites',\n",
       " 'fecal',\n",
       " 'occupational',\n",
       " 'phnotf',\n",
       " 'okcfox',\n",
       " 'hipster',\n",
       " 'wwwcn',\n",
       " 'zhzvprzbgq',\n",
       " 'litany',\n",
       " 'mins',\n",
       " 'occur',\n",
       " 'moferadio',\n",
       " 'dja',\n",
       " 'wasp',\n",
       " 'clean',\n",
       " 'zergele',\n",
       " 'tiffanyfrizzell',\n",
       " 'earrings',\n",
       " 'cleavage',\n",
       " 'barkevious',\n",
       " 'firms',\n",
       " 'earbuds',\n",
       " 'hr',\n",
       " 'worldpay',\n",
       " 'hunhry',\n",
       " 'tfx',\n",
       " 'col',\n",
       " 'mjles',\n",
       " 'hv',\n",
       " 'oppressed',\n",
       " 'mistreated',\n",
       " 'lamarcus',\n",
       " 'solano',\n",
       " 'ianokavo',\n",
       " 'murlo',\n",
       " 'annihilating',\n",
       " 'jgvhw',\n",
       " 'wqixgmhfh',\n",
       " 'trans',\n",
       " 'pantherattack',\n",
       " 'eb',\n",
       " 'pancakes',\n",
       " 'bjojvm',\n",
       " 'jolie',\n",
       " 'qjgoyci',\n",
       " 'lessons',\n",
       " 'bbcmtd',\n",
       " 'sniping',\n",
       " 'primarily',\n",
       " 'ptaelgv',\n",
       " 'bonhomme',\n",
       " 'kissing',\n",
       " 'stout',\n",
       " 'feeding',\n",
       " 'papi',\n",
       " 'tve',\n",
       " 'dependency',\n",
       " 'no_periferico',\n",
       " 'sunshine',\n",
       " 'end',\n",
       " 'half',\n",
       " 'limit',\n",
       " 'frvrgrateful',\n",
       " 'zq',\n",
       " 'buren',\n",
       " 'lying',\n",
       " 'pbban',\n",
       " 'ptvfuh',\n",
       " 'ejymkzpeex',\n",
       " 'straighten',\n",
       " 'italian',\n",
       " 'sincere',\n",
       " 'attention',\n",
       " 'curfew',\n",
       " 'lngclzsj',\n",
       " 'vpvj',\n",
       " 'denton',\n",
       " 'math',\n",
       " 'hunchback',\n",
       " 'crystal_blaz',\n",
       " 'xljnav',\n",
       " 'israel',\n",
       " 'tyler',\n",
       " 'closures',\n",
       " 'mi',\n",
       " 'nnf',\n",
       " 'otratmetlife',\n",
       " 'vofj',\n",
       " 'stood',\n",
       " 'aba',\n",
       " 'day',\n",
       " 'languishing',\n",
       " 'splifs',\n",
       " 'routes',\n",
       " 'jimskiv',\n",
       " 'coated',\n",
       " 'efs',\n",
       " 'xhlbxji',\n",
       " 'finite',\n",
       " 'usheekxm',\n",
       " 'romeocrow',\n",
       " 'unexercised',\n",
       " 'lindasocvat',\n",
       " 'kpkt',\n",
       " 'pioy',\n",
       " 'gains',\n",
       " 'sosfamupdater',\n",
       " 'vjhpvlnbaw',\n",
       " 'wyrmwood',\n",
       " 'lolol',\n",
       " 'uoozxaus',\n",
       " 'stung',\n",
       " 'n',\n",
       " 'malaysian',\n",
       " 'injuries',\n",
       " 'denying',\n",
       " 'future',\n",
       " 'aute',\n",
       " 'troyslaby',\n",
       " 'mbataweel',\n",
       " 'gon',\n",
       " 'lethbridge',\n",
       " 'increased',\n",
       " 'europe',\n",
       " 'ztcmsru',\n",
       " 'pletch',\n",
       " 'stool',\n",
       " 'thnexicgqe',\n",
       " 'hkbpqdncba',\n",
       " 'gv',\n",
       " 'justjon',\n",
       " 'putting',\n",
       " 'joke',\n",
       " 'skinless',\n",
       " 'salt',\n",
       " 'bind',\n",
       " 'sammy',\n",
       " 'rec',\n",
       " 'steep',\n",
       " 'aauizggc',\n",
       " 'illusions',\n",
       " 'diasporas',\n",
       " 'askcharley',\n",
       " 'ablz',\n",
       " 'nyse',\n",
       " 'rny',\n",
       " 'qh',\n",
       " 'zsop',\n",
       " 'rivalry',\n",
       " 'len',\n",
       " 'backups',\n",
       " 'outright',\n",
       " 'hand',\n",
       " 'vintage',\n",
       " 'item',\n",
       " 'cold',\n",
       " 'hendricks',\n",
       " 'adumbbb',\n",
       " 'egkveb',\n",
       " 'click',\n",
       " 'freshman',\n",
       " 'blossom',\n",
       " 'creamfields',\n",
       " 'bytsfms',\n",
       " 'lolly_knickers',\n",
       " 'fuckface',\n",
       " 'texas',\n",
       " 'gk',\n",
       " 'anymore',\n",
       " 'marek',\n",
       " 'woz',\n",
       " 'candace_dx',\n",
       " 'yhaqa',\n",
       " 'speak',\n",
       " 'mesgcngaz',\n",
       " 'engineering',\n",
       " 'coe',\n",
       " 'allocating',\n",
       " 'helping',\n",
       " 'hitch',\n",
       " 'west',\n",
       " 'msnbc',\n",
       " 'jetixrestored',\n",
       " 'collide',\n",
       " 'buddy',\n",
       " 'irhwg',\n",
       " 'orchs',\n",
       " 'cvjyml',\n",
       " 'karachi',\n",
       " 'eudwnfyuem',\n",
       " 'chaser',\n",
       " 'constantly',\n",
       " 'ratio',\n",
       " 'cfouwpbrcg',\n",
       " 'sonofbaldwin',\n",
       " 'janiethekillr',\n",
       " 'awakenings',\n",
       " 'khrone',\n",
       " 'tx',\n",
       " 'practitioner',\n",
       " 'hcsm',\n",
       " 'irish',\n",
       " 'charleston',\n",
       " 'teemo',\n",
       " 'siena',\n",
       " 'gaining',\n",
       " 'king',\n",
       " 'irhh',\n",
       " 'agq',\n",
       " 'redblood',\n",
       " 'bring',\n",
       " 'suffering',\n",
       " 'shadowflame',\n",
       " 'aivrbr',\n",
       " 'uqqi',\n",
       " 'lean',\n",
       " 'korzhonov',\n",
       " 'understand',\n",
       " 'infrastructure',\n",
       " 'utpmm',\n",
       " 'free',\n",
       " 'usg',\n",
       " 'ljntejgmb',\n",
       " 'mgidvbm',\n",
       " 'criminals',\n",
       " 'frontpage',\n",
       " 'irrespective',\n",
       " 'khsbzkfd',\n",
       " 'rdn',\n",
       " 'loo',\n",
       " 'wjljq',\n",
       " 'cleanup',\n",
       " 'ridiculously',\n",
       " 'zqoscqd',\n",
       " 'officer',\n",
       " 'escaped',\n",
       " 'soonersportstv',\n",
       " 'mtho',\n",
       " 'ogun',\n",
       " 'ukraine',\n",
       " 'hoffman',\n",
       " 'fabvlvn',\n",
       " 'officialrealrap',\n",
       " 'knott',\n",
       " 'electrical',\n",
       " 'cambridge',\n",
       " 'antonio',\n",
       " 'benaffleck',\n",
       " 'gag',\n",
       " 'cigarette',\n",
       " 'ih',\n",
       " 'tmmorvxswz',\n",
       " 'stew',\n",
       " 'cantmakeitup',\n",
       " 'vcsafx',\n",
       " 'awv',\n",
       " 'sugar',\n",
       " 'reader',\n",
       " 'cupcake',\n",
       " 'resolved',\n",
       " 'roof',\n",
       " 'kaccpk',\n",
       " 'naemolgo',\n",
       " 'tomorrow',\n",
       " 'craykain',\n",
       " 'sfgiants',\n",
       " 'vxeff',\n",
       " 'rì',\n",
       " 'omjmtu',\n",
       " 'ritzy_jewels',\n",
       " 'cia',\n",
       " 'raì¼l',\n",
       " 'aif',\n",
       " 'diebold',\n",
       " 'sailors',\n",
       " 'financial',\n",
       " 'indiakomuntorjawabdo',\n",
       " 'blockage',\n",
       " 'pqhq',\n",
       " 'jxs',\n",
       " 'flgovscott',\n",
       " 'snowstorm',\n",
       " 'putin',\n",
       " 'behalf',\n",
       " 'horn',\n",
       " 'depression',\n",
       " 'bitcoin',\n",
       " 'relief',\n",
       " 'dtour',\n",
       " 'hastle',\n",
       " 'recovery',\n",
       " 'picture',\n",
       " 'honey',\n",
       " 'nwlha',\n",
       " 'follower',\n",
       " 'qzbd',\n",
       " 'sstj',\n",
       " 'clear',\n",
       " 'fbi',\n",
       " 'ljws',\n",
       " 'yuppies',\n",
       " 'spencers',\n",
       " 'wheeler',\n",
       " 'capsizes',\n",
       " 'wilson',\n",
       " 'clegg',\n",
       " 'jacksonville',\n",
       " 'zgiupn',\n",
       " 'laid',\n",
       " 'kdthctemv',\n",
       " 'rachelrofe',\n",
       " 'paxton',\n",
       " 'nt',\n",
       " 'wet',\n",
       " 'cowx',\n",
       " 'nuys',\n",
       " 'bestnaijamade',\n",
       " 'palm',\n",
       " 'puns',\n",
       " 'hikdc',\n",
       " 'playstation',\n",
       " 'yiraneuni',\n",
       " 'droughts',\n",
       " 'asburyparkpress',\n",
       " 'tui',\n",
       " 'lubnw',\n",
       " 'uglypeople',\n",
       " 'nuke',\n",
       " 'gexynbh',\n",
       " 'hickson',\n",
       " 'yd',\n",
       " 'retro',\n",
       " 'worker',\n",
       " 'vela',\n",
       " 'champ',\n",
       " 'olpakz',\n",
       " 'umntu',\n",
       " 'plant',\n",
       " 'cstsmith',\n",
       " '__',\n",
       " 'ngata',\n",
       " 'bulletin',\n",
       " 'gin',\n",
       " 'kurds',\n",
       " 'void',\n",
       " 'transwomen',\n",
       " 'riwup',\n",
       " 'kapokekito',\n",
       " 'mfs',\n",
       " 'premature',\n",
       " 'duststorm',\n",
       " 'knowing',\n",
       " 'plaza',\n",
       " 'mbtb',\n",
       " 'writers',\n",
       " 'åç',\n",
       " 'yelling',\n",
       " 'pitmix',\n",
       " 'penetrate',\n",
       " 'wdseihyqu',\n",
       " 'conklin',\n",
       " 'exacerbated',\n",
       " 'gansey',\n",
       " 'blizzard_draco',\n",
       " 'givebackkalinwhiteaccount',\n",
       " 'tysta',\n",
       " 'communication',\n",
       " 'ûónegligence',\n",
       " 'actively',\n",
       " 'micom',\n",
       " 'qouxigdtbz',\n",
       " 'tt',\n",
       " 'anjem',\n",
       " 'xlq',\n",
       " 'wisdc',\n",
       " 'deviating',\n",
       " 'involving',\n",
       " 'kvjh',\n",
       " 'doningtondash',\n",
       " 'trs',\n",
       " 'pod',\n",
       " 'thedailybeast',\n",
       " 'towel',\n",
       " 'dragneel',\n",
       " 'mgk',\n",
       " 'needs',\n",
       " 'zrtrpl',\n",
       " 'justinejayyy',\n",
       " 'tovud',\n",
       " 'intersection',\n",
       " 'xnto',\n",
       " 'sour',\n",
       " 'escape',\n",
       " 'hearitfrompatty',\n",
       " 'yankees',\n",
       " 'tsbtigdsdt',\n",
       " 'rgj',\n",
       " 'vjolc',\n",
       " 'rig',\n",
       " 'fighters',\n",
       " 'ruthann',\n",
       " 'dissertation',\n",
       " 'bethlehem',\n",
       " 'moir',\n",
       " 'wfxbaqmbk',\n",
       " 'artisteoftheweekfact',\n",
       " 'wnuqqatttp',\n",
       " 'rand',\n",
       " 'bastard',\n",
       " 'masonite',\n",
       " 'employee',\n",
       " 'artist',\n",
       " 'imullbvued',\n",
       " 'soonermagic_',\n",
       " 'let',\n",
       " 'complaints',\n",
       " 'antony',\n",
       " 'sydtraffic',\n",
       " 'exs',\n",
       " 'trunk',\n",
       " 'withdraw',\n",
       " 'rmucfjcazr',\n",
       " 'voyruxcrin',\n",
       " 'bigger',\n",
       " 'idwpublishing',\n",
       " 'grandpa',\n",
       " 'ofr',\n",
       " 'xmmc',\n",
       " 'must',\n",
       " 'zrn',\n",
       " 'hyider_ghost',\n",
       " 'chicken',\n",
       " 'xrrk',\n",
       " 'ennullkzm',\n",
       " 'marin',\n",
       " 'slums',\n",
       " 'medinah',\n",
       " 'prosyn',\n",
       " 'imported',\n",
       " 'wishlist',\n",
       " 'cus',\n",
       " 'tuesday',\n",
       " 'justintrudeau',\n",
       " 'wrongdejavu',\n",
       " 'mizuta',\n",
       " 'sectors',\n",
       " 'wielding',\n",
       " 'pir',\n",
       " 'fresno',\n",
       " 'mcilroy',\n",
       " 'link',\n",
       " 'creek',\n",
       " 'watsmxytva',\n",
       " 'udkesj',\n",
       " 'qsu',\n",
       " 'prxeul',\n",
       " 'yyeso',\n",
       " 'michel',\n",
       " 'crashsterling',\n",
       " 'zqrcptlrum',\n",
       " 'sf',\n",
       " 'fv',\n",
       " 'tzsqe',\n",
       " 'singles',\n",
       " 'keegan',\n",
       " 'rlpttkbg',\n",
       " 'rains',\n",
       " 'imkeepingmydayjob',\n",
       " 'laighign',\n",
       " 'wqtdnp',\n",
       " 'protector',\n",
       " 'cramer',\n",
       " 'africa',\n",
       " 'dnq',\n",
       " 'thugging',\n",
       " 'xowli',\n",
       " 'strain',\n",
       " 'arvindkejriwal',\n",
       " 'airhead',\n",
       " 'evangelical',\n",
       " 'fun',\n",
       " 'debris',\n",
       " 'tosu',\n",
       " 'hua',\n",
       " 'appeared',\n",
       " 'izaknpjeqw',\n",
       " 'cortneymo_',\n",
       " 'qckq',\n",
       " 'qwnglkos',\n",
       " 'devise',\n",
       " 'flowers',\n",
       " 'dhgavw',\n",
       " 'junk',\n",
       " 'syringetoanger',\n",
       " 'estellasrevenge',\n",
       " 'adjuster',\n",
       " 'qjuu',\n",
       " 'dailykos',\n",
       " 'goats',\n",
       " 'dystopian',\n",
       " 'thisisfaz',\n",
       " 'ztonvgubvm',\n",
       " 'buy',\n",
       " 'lucypalladino',\n",
       " 'revealing',\n",
       " 'realhiphop',\n",
       " 'ripples',\n",
       " 'funko',\n",
       " 'indecisiveness',\n",
       " 'somehow',\n",
       " 'nana',\n",
       " 'pwpsfx',\n",
       " 'ncms',\n",
       " 'definite',\n",
       " 'aurugjegiq',\n",
       " 'wpo',\n",
       " 'evidence',\n",
       " 'zippers',\n",
       " 'slips',\n",
       " 'supply',\n",
       " 'wipes',\n",
       " 'tnu',\n",
       " 'pledge',\n",
       " 'wht',\n",
       " 'birth',\n",
       " 'zimmerman',\n",
       " 'deedee_casey',\n",
       " 'alarms',\n",
       " 'kamkasteiiano',\n",
       " 'gaheujruju',\n",
       " 'gpxqbyzyu',\n",
       " 'gates',\n",
       " 'landslide',\n",
       " 'cup',\n",
       " 'tyyfg',\n",
       " 'orchardalley',\n",
       " 'nickscomics',\n",
       " 'egcv',\n",
       " 'beard',\n",
       " 'event',\n",
       " 'dessicated',\n",
       " 'grenade',\n",
       " 'sport_en',\n",
       " 'crunchy',\n",
       " 'mumbaitimes',\n",
       " 'khq',\n",
       " 'passenger',\n",
       " 'dmassa',\n",
       " 'gravy',\n",
       " 'reserved',\n",
       " 'scottwalker',\n",
       " 'sorrower',\n",
       " 'motion',\n",
       " 'dirumah',\n",
       " 'hacks',\n",
       " 'gunmen',\n",
       " 'nook',\n",
       " 'bhb',\n",
       " 'bizzlemahomie',\n",
       " 'consciousness',\n",
       " 'coming',\n",
       " 'uiqsfgzoox',\n",
       " 'evaaasr',\n",
       " 'montetjwitter',\n",
       " 'bubble',\n",
       " 'hush',\n",
       " 'powerlines',\n",
       " 'sanonofre',\n",
       " 'jx',\n",
       " 'lqjjy',\n",
       " 'lvf',\n",
       " 'colin',\n",
       " 'cools',\n",
       " 'dougkessler',\n",
       " 'witches',\n",
       " 'trying',\n",
       " 'pljx',\n",
       " 'female',\n",
       " 'appointment',\n",
       " 'ivrzojzv',\n",
       " 'huffpostarts',\n",
       " 'unqualified',\n",
       " 'pelosi',\n",
       " 'ctijdpxabk',\n",
       " 'sweeping',\n",
       " 'ljylxz',\n",
       " 'guild',\n",
       " 'gpyw',\n",
       " 'ewnunp',\n",
       " 'replaced',\n",
       " 'nbc',\n",
       " 'plotted',\n",
       " 'suruc',\n",
       " 'jfb',\n",
       " 'whoa',\n",
       " 'rtrrt',\n",
       " 'off',\n",
       " 'applied',\n",
       " 'mnce',\n",
       " 'facebook',\n",
       " 'jaydennotjared',\n",
       " 'legionstrackandfield',\n",
       " 'amateur',\n",
       " 'calum',\n",
       " 'flesh',\n",
       " 'mmgsyahdzb',\n",
       " 'hopped',\n",
       " 'libby',\n",
       " 'carajdeievingnc',\n",
       " 'mount',\n",
       " 'temps',\n",
       " 'bioterror',\n",
       " 'dailytimesngr',\n",
       " 'note',\n",
       " 'lavapixcom',\n",
       " 'screeching',\n",
       " 'loner',\n",
       " 'rxw',\n",
       " 'fevwarrior',\n",
       " 'famineåêmemories',\n",
       " 'theevilolives',\n",
       " 'nkgp',\n",
       " 'om',\n",
       " 'nosvu',\n",
       " 'courtney',\n",
       " 'tssxphufe',\n",
       " 'doone',\n",
       " 'xhnews',\n",
       " 'elqlopfk',\n",
       " 'hmwhob',\n",
       " 'owgv',\n",
       " 'pediatric',\n",
       " 'jjmpmos',\n",
       " 'craekc',\n",
       " 'jeez',\n",
       " 'gxqwd',\n",
       " 'mixes',\n",
       " 'rochdale',\n",
       " 'candy',\n",
       " 'leader',\n",
       " 'bdotq',\n",
       " 'eco',\n",
       " 'ftmu',\n",
       " 'ourvl',\n",
       " 'diggin',\n",
       " 'mnddb',\n",
       " 'marine',\n",
       " 'accustomed',\n",
       " 'esemjrn',\n",
       " 'bluewestlo',\n",
       " 'blackinamerica',\n",
       " 'thanku',\n",
       " 'rbi',\n",
       " 'xrdwr',\n",
       " 'piprhys',\n",
       " 'duda',\n",
       " 'ksc',\n",
       " 'correction',\n",
       " 'metallica',\n",
       " 'fundwhen',\n",
       " 'eunice_njoki',\n",
       " 'qxh',\n",
       " 'coaster',\n",
       " 'wimbledon',\n",
       " 'yag',\n",
       " 'thestrain',\n",
       " 'vhbw',\n",
       " 'jslxtq',\n",
       " 'janenelson',\n",
       " 'vii',\n",
       " 'bookboost',\n",
       " 'shall',\n",
       " 'alternatives',\n",
       " 'prablematicla',\n",
       " 'uwijn',\n",
       " 'lubbock',\n",
       " 'clothing',\n",
       " 'mackayim',\n",
       " 'xzv',\n",
       " 'uni',\n",
       " 'azimel',\n",
       " 'asshole',\n",
       " 'qyn',\n",
       " 'ucudwiu',\n",
       " 'donnie',\n",
       " 'drinks',\n",
       " 'vetm',\n",
       " 'clever',\n",
       " 'scxfc',\n",
       " 'oktxduo',\n",
       " 'bushman',\n",
       " 'piperwearsthepants',\n",
       " 'dreamoforgonon',\n",
       " 'txetcysm',\n",
       " 'vwr',\n",
       " 'pronouncing',\n",
       " 'mmiye',\n",
       " 'setanta',\n",
       " 'schulz',\n",
       " 'twister',\n",
       " 'jwsyrqr',\n",
       " 'szeapueuvy',\n",
       " 'clyj',\n",
       " 'rabaa',\n",
       " 'xli',\n",
       " 'oez',\n",
       " 'cllrraymogford',\n",
       " 'neil_eastwood',\n",
       " 'wud',\n",
       " 'combined',\n",
       " 'qd',\n",
       " 'jycpf',\n",
       " 'cumslut_',\n",
       " 'mats',\n",
       " 'gs',\n",
       " 'latssuo',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced109f",
   "metadata": {},
   "source": [
    "Before trying other algorithm let's clean a little more our dataframe. We can see that there are a lot of columns that are indicating the presence of \"useless\" words insind tweets, we need to delete these columns. To select which columns to delete, we'll consider that a word is useless when it appears in only 1 tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3d02492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7596\n",
       "1      17\n",
       "Name: reported, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words['reported'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b329f3",
   "metadata": {},
   "source": [
    "As an example, above we displayed that the words \"reported\" is only in 17 tweets out of 7613 tweets.\n",
    "\n",
    "Let's count in how many tweets each word appears and only select the one that appears in more than one tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d1da59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denies          1\n",
      "ofcourse        1\n",
      "ijzcytbffo      1\n",
      "exact           1\n",
      "stuartbroad     1\n",
      "               ..\n",
      "outbound        1\n",
      "kwwwkwwwk       1\n",
      "freebesieged    1\n",
      "raf             1\n",
      "tantrums        1\n",
      "Length: 22261, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "a = training_words[vocabulary].sum(axis = 0)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67d42f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6995"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_words = pd.Series(training_words.copy().drop(['text_', 'target_'], axis =1).sum(axis = 0))\n",
    "useful_words = sum_words[sum_words > 1]\n",
    "useful_words = list(useful_words.index)\n",
    "len(useful_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d1689",
   "metadata": {},
   "source": [
    "We managed to delete a little more than 600 useless words, let's see if it was useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc549aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X2 = training_words[useful_words]\n",
    "all_y2 = training_words['target_']\n",
    "\n",
    "\n",
    "train_X2, test_X2, train_y2, test_y2 = train_test_split(\n",
    "    all_X2, all_y2, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dda7e05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8108995403808273\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 1000)\n",
    "lr.fit(train_X2, train_y2)\n",
    "predictions = lr.predict(test_X2)\n",
    "accuracy = accuracy_score(test_y2, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41454d",
   "metadata": {},
   "source": [
    "We got the same result of 81 %.\n",
    "\n",
    "Let's try with other algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2625b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def plot_dict(dictionary):\n",
    "    pd.Series(dictionary).plot.bar(figsize=(9,6),\n",
    "                                   ylim=(0.57,0.61),rot=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "096376b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_scores = dict()\n",
    "\n",
    "for k in range(1,10,2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, all_X, all_y, cv = 10)\n",
    "    accuracy_knn = scores.mean()\n",
    "    knn_scores[k] = accuracy_knn\n",
    "\n",
    "plot_dict(knn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e33faf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.5758614683677024,\n",
       " 3: 0.5795342845613417,\n",
       " 5: 0.5847900090018314,\n",
       " 7: 0.5812437702842992,\n",
       " 9: 0.5812441151820543}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aae651",
   "metadata": {},
   "source": [
    "The K-neighbors algorithm doesn't seems to achieve good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e375a",
   "metadata": {},
   "source": [
    "Let's drop the stopwords in English from the columns so that our algorithm become more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "830bf302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['over', 'having', 'not', 'o', 'as', 'wasn', 'her', \"it's\", 'and', 'if', 'of', 'then', \"you'd\", 'wouldn', 'its', 'doing', 'me', 'there', 'below', 'down', 'll', 'such', 'to', \"weren't\", 'being', 'haven', 'does', 'from', \"shouldn't\", 'some', 'while', 'yourself', 'did', 'after', 'which', \"wasn't\", 's', \"needn't\", 'other', 'hadn', 'my', 'y', 'needn', 'who', 'he', \"that'll\", 'ourselves', 'his', 've', 'aren', 'ain', \"couldn't\", 'a', 'both', 'yours', 'can', 'it', \"wouldn't\", 'that', 'most', 'all', 'any', \"you're\", 'same', 'between', 'in', 'hasn', 'own', 'at', 'we', 'an', 'itself', 'once', 'only', 'more', 'this', 'have', 'won', 'on', \"hasn't\", 'why', 'shan', 'didn', 'him', 'doesn', \"aren't\", 'ours', 'mustn', \"she's\", 'through', 'few', \"doesn't\", 'mightn', 'further', 'but', \"won't\", 'yourselves', \"haven't\", 'before', 'isn', 'don', 'hers', 're', 'what', 'very', 'theirs', 'just', \"hadn't\", 'i', 'themselves', 'until', 'when', 'where', 'out', 'again', \"you've\", 'the', 'these', 'above', 'will', 'been', 'was', 'about', 'd', 'ma', 'now', 'weren', \"didn't\", 'with', 'your', \"mightn't\", 'they', 'so', 'off', 'were', 'whom', 'be', 'their', 'up', 'each', 'am', 'for', 'you', 'herself', 'them', 'are', \"mustn't\", 'by', 'into', 'nor', \"should've\", \"don't\", 'how', 'm', 'than', 'our', 'under', 'those', 'because', 'myself', 't', \"isn't\", 'against', 'do', 'himself', 'here', 'shouldn', \"shan't\", 'has', 'had', 'too', \"you'll\", 'couldn', 'is', 'during', 'or', 'should', 'no', 'she']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = list(set(stopwords.words('english')))\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3798d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6995 6850\n"
     ]
    }
   ],
   "source": [
    "useful_words2 = []\n",
    "for word in useful_words:\n",
    "    if word not in stops:\n",
    "        useful_words2.append(word)\n",
    "\n",
    "print(len(useful_words), len(useful_words2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48a8a0",
   "metadata": {},
   "source": [
    "We got rid of 145 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63067d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X3 = training_words[useful_words2]\n",
    "all_y3 = training_words['target_']\n",
    "\n",
    "\n",
    "train_X3, test_X3, train_y3, test_y3 = train_test_split(\n",
    "    all_X3, all_y3, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e82c6f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8049901510177282\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 1000)\n",
    "lr.fit(train_X3, train_y3)\n",
    "predictions = lr.predict(test_X3)\n",
    "accuracy = accuracy_score(test_y3, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7525c455",
   "metadata": {},
   "source": [
    "We lost 0.5 % accuracy by removing the stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e747f873",
   "metadata": {},
   "source": [
    "After those few tests, we have decided to keep all the words that were judged \"useless\".\n",
    "\n",
    "With this in mind, the algorithm was applied to the holdout dataset and the predictions submitted to Kaggle. They have got us a score of 0.79773 out of 1. Excluding the perfect scores of the leaderboard that were obtained because the answers are available online, the best scores goes around 0.85."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
